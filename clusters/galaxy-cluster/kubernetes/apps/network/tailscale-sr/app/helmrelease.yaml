---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: tailscale-sr
spec:
  interval: 1h
  chartRef:
    kind: OCIRepository
    name: app-template
    namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  values:
    controllers:
      tailscale-sr:
        type: deployment
        replicas: 1
        containers:
          app:
            env:
              NO_AUTOUPDATE: true
              PORT: &tailnetPort 45387
              TS_EXTRA_ARGS: --accept-routes --advertise-exit-node --advertise-tags=tag:subnet-router
              TS_HOSTNAME: "tailscale-subnet-router"
              TS_KUBE_SECRET: ""
              TS_ROUTES: "${NET_MANAGEMENT_CIDR},${NET_HOME_CIDR},${NET_SMARTHOME_CIDR},${NET_LEGACY_HOME_CIDR}"
              TS_STATE_DIR: &path /tmp
              TS_TAILSCALED_EXTRA_ARGS: --debug=0.0.0.0:9001
              TS_USERSPACE: true
              TZ: "${CLUSTER_TIME_ZONE}"
            image:
              repository: ghcr.io/tailscale/tailscale
              tag: v1.86.5@sha256:9e2bfdd9e2ce724df53f976d06a4a9933aa730dc655ace42798f4c73735d1cac
            probes:
              liveness: &probes
                custom: true
                enabled: true
                spec:
                  failureThreshold: 3
                  httpGet:
                    path: /debug/pprof/
                    port: &tailscalePort 9001
                  initialDelaySeconds: 15
                  periodSeconds: 20
                  timeoutSeconds: 1
              readiness: *probes
            resources:
              limits:
                cpu: 1
                memory: 420Mi
              requests:
                cpu: 50m
                memory: 250Mi
            securityContext:
              allowPrivilegeEscalation: false
              capabilities:
                add:
                  - NET_BIND_SERVICE
                drop:
                  - ALL
              readOnlyRootFilesystem: true
    defaultPodOptions:
      securityContext:
        fsGroup: 568
        runAsGroup: 568
        runAsNonRoot: true
        runAsUser: 568
        seccompProfile:
          type: RuntimeDefault
      shareProcessNamespace: true
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app.kubernetes.io/name
                      operator: In
                      values:
                        - blocky
                topologyKey: kubernetes.io/hostname

    service:
      app:
        controller: blocky
        labels:
          network: lan
        annotations:
          "lbipam.cilium.io/sharing-key": "blocky-shared"
          "lbipam.cilium.io/ips": "192.168.31.36"
        ports:
          dns-udp:
            port: 53
            protocol: UDP
          dns-tcp:
            port: 53
            protocol: TCP
        type: LoadBalancer

      metrics:
        controller: blocky
        type: ClusterIP
        ports:
          http:
            port: 4000
            primary: true